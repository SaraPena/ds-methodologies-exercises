{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import acquire\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = acquire.get_iris_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize\n",
    "\n",
    "- info\n",
    "- describe\n",
    "- head/tail\n",
    "- value_counts\n",
    "- shape\n",
    "- isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df. describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.value_counts(bins=10, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data\n",
    "\n",
    "- drop columns\n",
    "- fillna\n",
    "- split\n",
    "- impute mean, mode, median: SimpleImputer\n",
    "- integer encodeing: LabelEncoder\n",
    "- one hot encodeing: OneHotEncoder\n",
    "- scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deck values only has 203 values, and 688 nulls. We don't think we will be able to gather much information from that column so we will drop it.\n",
    "df.drop(columns =['deck'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will then fill our null values with 'np.nan'. Down the road this will cause less errors with functions, or we will be able to find the values causing errors more easily\n",
    "df.fillna(np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then split data into train & test using scikit learn model selection function train_test_split.\n",
    "train, test = train_test_split(df, train_size = .8, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute mean, mode, median using SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.embarked.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are 2 NaN values in this data. We will fill them using the SimpleImputer, 'most_frequent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SimpleImputer Object\n",
    "imp_mode = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "imp_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the SimpleImputer Object to the train data. This again creates an object.\n",
    "imp_mode.fit(train[['embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the train data using the scaler object SimpleImputer that has been fit to train\n",
    "train['embarked'] = imp_mode.transform(train[['embarked']])\n",
    "train['embarked'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data using the scaler object SimpleImputer that has been fit to train.\n",
    "test['embarked'] = imp_mode.transform(test[['embarked']])\n",
    "test['embarked'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the value_counts() for age\n",
    "train.age.value_counts(dropna=False).head(), test.age.value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 148 NaN values in the train, and 29 NaN values in the test. We will use the SimpleImputer to fill these with the median age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SimpleImputer Object.\n",
    "imp_median = SimpleImputer(missing_values = np.nan, strategy = 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can fit and transform the test data in one step using fit_transform\n",
    "train['age'] = imp_median.fit_transform(train[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.age.value_counts().head()\n",
    "# There are no NaN values in our test data. So we do not need to fill in any values with the SimpleImputer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding\n",
    "\n",
    "1. Integer encoding\n",
    "2. one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to make our categorical variable 'embarked' labeled with numbers instead of letters. Right now 'embarked' is an object datatype\n",
    "# Create our encoder object\n",
    "int_encoder = LabelEncoder()\n",
    "int_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the encoder object to our train data. \n",
    "int_encoder.fit(train.embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform the data using the encoder object that has been fitted to the train data.\n",
    "train.embarked = int_encoder.transform(train.embarked)\n",
    "train.embarked.value_counts()\n",
    "# This data is labeled by alpha S - 2, Q - 128, C - 67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to create a data frame that will put our values for int_encoded data into rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an 2-D array from the new train.embarked data to use in our transform for OneHotEncode.\n",
    "embarked_array = np.array(train.embarked).reshape(len(train.embarked),1)\n",
    "embarked_array[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OneHotEncoder Object\n",
    "ohe = OneHotEncoder(sparse = False, categories = 'auto')\n",
    "ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the OnehotEncoder to the embarked_array that contains our train data.\n",
    "embarked_ohe = ohe.fit_transform(embarked_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also transform our test data into 3 columns for our categories.\n",
    "# transform the test.embarked data into numerical labeled data.\n",
    "test.embarked = int_encoder.transform(test.embarked)\n",
    "test.embarked.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the test.embarked Series into a 2-D array to transform using OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_array = np.array(test.embarked).reshape(len(test.embarked),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_test_ohe = ohe.transform(embarked_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_test_ohe[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

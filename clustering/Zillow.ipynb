{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire (acquire.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zillow\n",
    "\n",
    "For the following, iterate through the steps you would take to create functions: write the code to do the following in a jupyter notebook, test it, convert to functions, then create the file to house those functions.\n",
    "\n",
    "You will have a zillow.ipynb file and a helper file for each section in the pipeline\n",
    "\n",
    "***acquire & summarize***\n",
    "\n",
    "1. Acquire data from mySQL using the python module to connect and query. you will want to end with a single dataframe. Make sure to include: the logerror, all fields related to the properties that are available. You will end up using all the tables in the database\n",
    "\n",
    "    - ***Be sure to do the correct join. We do not want to eliminate properties purely because they may have a null value for `airconditioningtypeid`***\n",
    "    \n",
    "    - only include properties with a transaction in 2017, and include only the last transaction for each property (so no duplicate property id's), along with zestimate error and date of transaction.\n",
    "    \n",
    "    - only include properties that include a latitude and longitude value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Wrangling\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Exploring\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "\n",
    "# default pandas decimal number display format.\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "pd.set_option(\"max_r\", 80)\n",
    "\n",
    "import acquire\n",
    "import prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactiondate</th>\n",
       "      <th>id</th>\n",
       "      <th>parcelid</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>basementsqft</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingclasstypeid</th>\n",
       "      <th>...</th>\n",
       "      <th>numberofstories</th>\n",
       "      <th>fireplaceflag</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>censustractandblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1727539</td>\n",
       "      <td>14297519</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>485,713.00</td>\n",
       "      <td>1,023,282.00</td>\n",
       "      <td>2,016.00</td>\n",
       "      <td>537,569.00</td>\n",
       "      <td>11,013.72</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>60,590,630,072,012.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1387261</td>\n",
       "      <td>17052889</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>88,000.00</td>\n",
       "      <td>464,000.00</td>\n",
       "      <td>2,016.00</td>\n",
       "      <td>376,000.00</td>\n",
       "      <td>5,672.48</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>61,110,010,023,006.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>11677</td>\n",
       "      <td>14186244</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>85,289.00</td>\n",
       "      <td>564,778.00</td>\n",
       "      <td>2,016.00</td>\n",
       "      <td>479,489.00</td>\n",
       "      <td>6,488.30</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>60,590,218,022,012.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2288172</td>\n",
       "      <td>12177905</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>108,918.00</td>\n",
       "      <td>145,143.00</td>\n",
       "      <td>2,016.00</td>\n",
       "      <td>36,225.00</td>\n",
       "      <td>1,777.51</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>60,373,001,001,006.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1970746</td>\n",
       "      <td>10887214</td>\n",
       "      <td>1.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>73,681.00</td>\n",
       "      <td>119,407.00</td>\n",
       "      <td>2,016.00</td>\n",
       "      <td>45,726.00</td>\n",
       "      <td>1,533.89</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>60,371,236,012,000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              logerror transactiondate       id  parcelid  \\\n",
       "0                 0.03      2017-01-01  1727539  14297519   \n",
       "1                 0.06      2017-01-01  1387261  17052889   \n",
       "2                 0.01      2017-01-01    11677  14186244   \n",
       "3                -0.10      2017-01-01  2288172  12177905   \n",
       "4                 0.01      2017-01-01  1970746  10887214   \n",
       "\n",
       "   airconditioningtypeid  architecturalstyletypeid         basementsqft  \\\n",
       "0                    nan                       nan                  nan   \n",
       "1                    nan                       nan                  nan   \n",
       "2                    nan                       nan                  nan   \n",
       "3                    nan                       nan                  nan   \n",
       "4                   1.00                       nan                  nan   \n",
       "\n",
       "           bathroomcnt           bedroomcnt  buildingclasstypeid  ...  \\\n",
       "0                 3.50                 4.00                  nan  ...   \n",
       "1                 1.00                 2.00                  nan  ...   \n",
       "2                 2.00                 3.00                  nan  ...   \n",
       "3                 3.00                 4.00                  nan  ...   \n",
       "4                 3.00                 3.00                  nan  ...   \n",
       "\n",
       "       numberofstories        fireplaceflag  structuretaxvaluedollarcnt  \\\n",
       "0                  nan                  nan                  485,713.00   \n",
       "1                 1.00                  nan                   88,000.00   \n",
       "2                 1.00                  nan                   85,289.00   \n",
       "3                  nan                  nan                  108,918.00   \n",
       "4                  nan                  nan                   73,681.00   \n",
       "\n",
       "     taxvaluedollarcnt       assessmentyear  landtaxvaluedollarcnt  \\\n",
       "0         1,023,282.00             2,016.00             537,569.00   \n",
       "1           464,000.00             2,016.00             376,000.00   \n",
       "2           564,778.00             2,016.00             479,489.00   \n",
       "3           145,143.00             2,016.00              36,225.00   \n",
       "4           119,407.00             2,016.00              45,726.00   \n",
       "\n",
       "             taxamount  taxdelinquencyflag   taxdelinquencyyear  \\\n",
       "0            11,013.72                None                  nan   \n",
       "1             5,672.48                None                  nan   \n",
       "2             6,488.30                None                  nan   \n",
       "3             1,777.51                None                  nan   \n",
       "4             1,533.89                None                  nan   \n",
       "\n",
       "    censustractandblock  \n",
       "0 60,590,630,072,012.00  \n",
       "1 61,110,010,023,006.00  \n",
       "2 60,590,218,022,012.00  \n",
       "3 60,373,001,001,006.00  \n",
       "4 60,371,236,012,000.00  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Summarizes the data you have just read into a dataframe in the ways we have discussed in previous models (sample view, datatypes, value counts, summary stats, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_option(\"display.max_rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_r\", 100)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_option(\"display.max_rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nulls_by_col\n",
    "\n",
    "3. Write a function that takes in a dataframe of observations and attributes and returns a dataframe where each row is an attribute name, the first column is the number of rows with missing values for that attribute, and the second column is percent of total rows that have missing values for that attribute. Run a function and document takeaways from this on how you want to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nulls_by_col(df):\n",
    "    # Look at the number missing.\n",
    "    num_missing = df.isnull().sum()\n",
    "        # num_missing.head(20)\n",
    "\n",
    "    # number of rows\n",
    "    rows = df.shape[0]\n",
    "        #rows\n",
    "\n",
    "    # percent missing\n",
    "    pct_missing = num_missing/rows\n",
    "        # pct_missing.head(20)\n",
    "\n",
    "    cols_missing = pd.DataFrame({'num_rows_missing': num_missing, 'pct_rows_missing': pct_missing})\n",
    "        #cols_missing.head(20)\n",
    "    \n",
    "    return cols_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_by_col(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nulls_by_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a function that takes in a dataframe and returns a dataframe with 3 columns: the number of columns missing, percent of columns missing, the numbner of rows with n columns missing. Run the function and document takeaways from this on you you want to handle the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nulls_by_row(df):\n",
    "    # Look as nulls by rows (axis = 1)\n",
    "    num_cols_missing = df.isnull().sum(axis=1)\n",
    "        # num_cols_missing\n",
    "    \n",
    "    # number of colums\n",
    "    columns = df.shape[1]\n",
    "    \n",
    "    # Pecents of colums missing \n",
    "    pct_cols_missing = num_cols_missing/columns * 100\n",
    "        #pct_cols_missing\n",
    "        #pct_cols_missing.value_counts().sort_index()\n",
    "    \n",
    "    # Amount of rows with missing columns and percentage\n",
    "    rows_missing = pd.DataFrame({'num_cols_missing': num_cols_missing, 'pct_cols_missing': pct_cols_missing}).reset_index().groupby(['num_cols_missing', 'pct_cols_missing']).count().rename(index = str, columns={'index':'num_rows'}).reset_index()\n",
    "\n",
    "    return rows_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_by_row(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type(df.transactiondate.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_value_counts(df):\n",
    "    for col in df.columns:\n",
    "        print(f'{col}:')\n",
    "        if df[col].dtype == 'object':\n",
    "            col_count = df[col].value_counts()\n",
    "        else:\n",
    "            if df[col].nunique() >= 35:\n",
    "                col_count = df[col].value_counts(bins=10, sort=False)\n",
    "            else:\n",
    "                col_count = df[col].value_counts()\n",
    "        print(col_count)\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_summary(df):\n",
    "    print(f'--- Shape:{df.shape}')\n",
    "    print('\\n--- Info:')\n",
    "    df.info()\n",
    "    print('\\n--- Descriptions:')\n",
    "    print(df.describe(include='all'))\n",
    "    print(f'\\n--- Nulls by Column:\\n {nulls_by_col(df)}')\n",
    "    print(f'\\n--- Nulls by Row:\\n {nulls_by_row(df)}')\n",
    "    print('\\n--- Value Counts:\\n')\n",
    "    print(df_value_counts(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.hist(figsize=(36, 80), bins=20)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(s, k):\n",
    "    \"\"\"\n",
    "    Given a series and a cutoff value, k, returns the upper outliers for the series.\n",
    "    \n",
    "    The values returned will be either 0 (if the point is not an outlier), or a number that indicated how far away from the upper bound the observation is.\n",
    "    \"\"\"\n",
    "    \n",
    "    q1, q3 = s.quantile([.25,.75])\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + k * iqr\n",
    "    lower_bound = q1 - k * iqr\n",
    "    return s.apply(lambda x: max([x - upper_bound,0])), s.apply(lambda x: min([x - lower_bound,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_outlier_columns(df,k):\n",
    "    \"\"\"\n",
    "    Add a column with the suffix _outliers for all the numeric\n",
    "    \"\"\"\n",
    "    for col in df.select_dtypes('number'):\n",
    "        df[col + '_lower_outliers'] = get_outliers(df[col],k)[1]\n",
    "        df[col + '_upper_outliers'] = get_outliers(df[col],k)[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_outlier_columns(df_single_unit, k = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove any properties that are likely to be something other than single unit properties. (e.g. no duplexes, not land/lot,...) There are multiple ways to estimate that a property is a single unit, and there is no single not a single \"right\" answer. But for this exercise, do not purely filter by unitcnt as we did previously. Add some new logic that will reduce the number of properties that are falsely removed. You might want to use #bedrooms, square_fee, unit type or the like to then identify those with unitcnt not defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.propertylandusetypeid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bathroomcnt.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.bedroomcnt.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.calculatedfinishedsquarefeet.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52168, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_single_unit = df[(df.propertylandusetypeid == 261) &\n",
    "                    (df.bedroomcnt > 0) &\n",
    "                    (df.bathroomcnt > 0)]\n",
    "df_single_unit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logerror                            0\n",
       "transactiondate                     0\n",
       "id                                  0\n",
       "parcelid                            0\n",
       "airconditioningtypeid           38563\n",
       "architecturalstyletypeid        52098\n",
       "basementsqft                    52121\n",
       "bathroomcnt                         0\n",
       "bedroomcnt                          0\n",
       "buildingclasstypeid             52168\n",
       "buildingqualitytypeid           18541\n",
       "calculatedbathnbr                  16\n",
       "decktypeid                      51781\n",
       "finishedfloor1squarefeet        47814\n",
       "calculatedfinishedsquarefeet        8\n",
       "finishedsquarefeet12              166\n",
       "finishedsquarefeet13            52168\n",
       "finishedsquarefeet15            52168\n",
       "finishedsquarefeet50            47814\n",
       "finishedsquarefeet6             52010\n",
       "fips                                0\n",
       "fireplacecnt                    44947\n",
       "fullbathcnt                        16\n",
       "garagecarcnt                    34202\n",
       "garagetotalsqft                 34202\n",
       "hashottuborspa                  50654\n",
       "heatingorsystemtypeid           18345\n",
       "latitude                            0\n",
       "longitude                           0\n",
       "lotsizesquarefeet                 354\n",
       "poolcnt                         41104\n",
       "poolsizesum                     51308\n",
       "pooltypeid10                    51725\n",
       "pooltypeid2                     51097\n",
       "pooltypeid7                     42191\n",
       "propertycountylandusecode           0\n",
       "propertylandusetypeid               0\n",
       "propertyzoningdesc              18479\n",
       "rawcensustractandblock              0\n",
       "regionidcity                     1028\n",
       "regionidcounty                      0\n",
       "regionidneighborhood            33240\n",
       "regionidzip                        23\n",
       "roomcnt                             0\n",
       "storytypeid                     52121\n",
       "threequarterbathnbr             45452\n",
       "typeconstructiontypeid          52092\n",
       "unitcnt                         18451\n",
       "yardbuildingsqft17              50242\n",
       "yardbuildingsqft26              52105\n",
       "yearbuilt                          40\n",
       "numberofstories                 37662\n",
       "fireplaceflag                   52087\n",
       "structuretaxvaluedollarcnt         72\n",
       "taxvaluedollarcnt                   1\n",
       "assessmentyear                      0\n",
       "landtaxvaluedollarcnt               1\n",
       "taxamount                           4\n",
       "taxdelinquencyflag              50108\n",
       "taxdelinquencyyear              50108\n",
       "censustractandblock               112\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_single_unit.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a function that will drop rows or columns based on the percent of values that are missing: handle_missing_values(df, prop_required_column, prop_required_row)\n",
    "\n",
    "    - The input\n",
    "        - A datframe\n",
    "        - A number between 0 and 1 that represents the proportion, for each column, of rows with non-missing values required to keep the column. i.e. if prop_required_column = .6, then you are requiring a column to have at least 60% of values not-NA(no more than 40% missing).\n",
    "        - A number between 0 and 1 that represents the proportion, of reach rows, of columns/variables with non-missing values required to keep the row. For example, if prop_required_row =.75, than you are requiring a row to have at least 75% of variables with non-missing value(no more than 25% missing).\n",
    "    - The output:\n",
    "        - The dataframe with the columns and rows dropped as indicated. ***Be sure to drop the columns prior to the rows in your function***\n",
    "    - hint:\n",
    "        - Look up the dropna documentation\n",
    "        - you will want to compute a threshold from your input values(prop_required) and a total number of rows or columns.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted columns:\n",
    "def remove_columns(df, cols_to_remove):\n",
    "    df = df.drop(columns = cols_to_remove)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values according to a set of required thresholds.\n",
    "def handle_missing_values(df, prop_required_column = .5, prop_required_row = .75):\n",
    "    threshold = int(round(prop_required_column*len(df.index)))\n",
    "    df.dropna(axis=1, thresh=threshold, inplace = True)\n",
    "    threshold = int(round(prop_required_row*len(df.columns)))\n",
    "    df.dropna(axis=0, thresh=threshold, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle_missing_values(df_single_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data frame by removing unwanted columns. Then remove columns and rows that did not have enough data set by a proportion for rows and columns.\n",
    "def data_prep(df, cols_to_remove=[], prop_required_column = .5, prop_required_row = .75):\n",
    "    df = remove_columns(df, cols_to_remove)\n",
    "    df = handle_missing_values(df, prop_required_column, prop_required_row)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52167, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_prep(df_single_unit)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52167 entries, 0 to 77379\n",
      "Data columns (total 32 columns):\n",
      "logerror                        52167 non-null float64\n",
      "transactiondate                 52167 non-null object\n",
      "id                              52167 non-null int64\n",
      "parcelid                        52167 non-null int64\n",
      "bathroomcnt                     52167 non-null float64\n",
      "bedroomcnt                      52167 non-null float64\n",
      "buildingqualitytypeid           33627 non-null float64\n",
      "calculatedbathnbr               52152 non-null float64\n",
      "calculatedfinishedsquarefeet    52160 non-null float64\n",
      "finishedsquarefeet12            52002 non-null float64\n",
      "fips                            52167 non-null float64\n",
      "fullbathcnt                     52152 non-null float64\n",
      "heatingorsystemtypeid           33823 non-null float64\n",
      "latitude                        52167 non-null float64\n",
      "longitude                       52167 non-null float64\n",
      "lotsizesquarefeet               51813 non-null float64\n",
      "propertycountylandusecode       52167 non-null object\n",
      "propertylandusetypeid           52167 non-null float64\n",
      "propertyzoningdesc              33689 non-null object\n",
      "rawcensustractandblock          52167 non-null float64\n",
      "regionidcity                    51139 non-null float64\n",
      "regionidcounty                  52167 non-null float64\n",
      "regionidzip                     52144 non-null float64\n",
      "roomcnt                         52167 non-null float64\n",
      "unitcnt                         33717 non-null float64\n",
      "yearbuilt                       52128 non-null float64\n",
      "structuretaxvaluedollarcnt      52095 non-null float64\n",
      "taxvaluedollarcnt               52166 non-null float64\n",
      "assessmentyear                  52167 non-null float64\n",
      "landtaxvaluedollarcnt           52166 non-null float64\n",
      "taxamount                       52163 non-null float64\n",
      "censustractandblock             52055 non-null float64\n",
      "dtypes: float64(27), int64(2), object(3)\n",
      "memory usage: 13.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6,037.00    33751\n",
       "6,059.00    14060\n",
       "6,111.00     4356\n",
       "Name: fips, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fips.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.buildingqualitytypeid.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.heatingorsystemtypeid.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.taxvaluedollarcnt.value_counts(dropna=False).sort_index().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(df[df.taxvaluedollarcnt.isna() == True].index)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Decide how to handle the remaining missing values:\n",
    "    - Fill with constant falue.\n",
    "    - Impute with mean, median, mode.\n",
    "    - Drop row/column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df, fill_value):\n",
    "    df.fillna(fill_value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
